{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "Ug5Qwu5yQ8iT",
        "outputId": "1e963a5b-081d-44ae-cde1-be5152b1701d"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      2\u001b[39m uploaded= files.upload()\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded= files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9Hnt1uURQ1u",
        "outputId": "b8ec11bf-5249-4299-fdc8-43a68f903404"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2mnGPTNHRRcO",
        "outputId": "e830b9fe-beda-46c9-ec30-b09539b18043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   polarity                                               text\n",
            "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
            "1         0  is upset that he can't update his Facebook by ...\n",
            "2         0  @Kenichan I dived many times for the ball. Man...\n",
            "3         0    my whole body feels itchy and like its on fire \n",
            "4         0  @nationwideclass no, it's not behaving at all....\n",
            "polarity\n",
            "0    800000\n",
            "1    800000\n",
            "Name: count, dtype: int64\n",
            "                                                text  \\\n",
            "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
            "1  is upset that he can't update his Facebook by ...   \n",
            "2  @Kenichan I dived many times for the ball. Man...   \n",
            "3    my whole body feels itchy and like its on fire    \n",
            "4  @nationwideclass no, it's not behaving at all....   \n",
            "\n",
            "                                          clean_text  \n",
            "0  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
            "1  is upset that he can't update his facebook by ...  \n",
            "2  @kenichan i dived many times for the ball. man...  \n",
            "3    my whole body feels itchy and like its on fire   \n",
            "4  @nationwideclass no, it's not behaving at all....  \n",
            "Train size: 1280000\n",
            "Test size: 320000\n",
            "TF-IDF shape (train): (1280000, 5000)\n",
            "TF-IDF shape (test): (320000, 5000)\n",
            "Bernoulli Naive Bayes Accuracy: 0.766478125\n",
            "SVM Accuracy: 0.79528125\n",
            "Logistic Regression Accuracy: 0.79539375\n",
            "\n",
            "BernoulliNB Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.75      0.76    159494\n",
            "           1       0.76      0.78      0.77    160506\n",
            "\n",
            "    accuracy                           0.77    320000\n",
            "   macro avg       0.77      0.77      0.77    320000\n",
            "weighted avg       0.77      0.77      0.77    320000\n",
            "\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           1       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           1       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load Sentiment140 data\n",
        "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None)\n",
        "df = df[[0, 5]]\n",
        "df.columns = ['polarity', 'text']\n",
        "print(df.head())\n",
        "\n",
        "# Keep only positive (4) and negative (0)\n",
        "df = df[df.polarity != 2]\n",
        "df['polarity'] = df['polarity'].map({0: 0, 4: 1})\n",
        "print(df['polarity'].value_counts())\n",
        "\n",
        "# Simple cleaning function\n",
        "def clean_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "print(df[['text', 'clean_text']].head())\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_text'], df['polarity'], test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Test size:\", len(X_test))\n",
        "\n",
        "# Vectorize text using TF-IDF (using binary features for BernoulliNB)\n",
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "print(\"TF-IDF shape (train):\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF shape (test):\", X_test_tfidf.shape)\n",
        "\n",
        "\n",
        "# Bernoulli Naive Bayes\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train_tfidf, y_train)\n",
        "bnb_pred = bnb.predict(X_test_tfidf)\n",
        "print(\"Bernoulli Naive Bayes Accuracy:\", accuracy_score(y_test, bnb_pred))\n",
        "\n",
        "# Support Vector Machine (LinearSVC)\n",
        "svm = LinearSVC(max_iter=1000)\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "svm_pred = svm.predict(X_test_tfidf)\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "\n",
        "# Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=100)\n",
        "logreg.fit(X_train_tfidf, y_train)\n",
        "logreg_pred = logreg.predict(X_test_tfidf)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_pred))\n",
        "\n",
        "# Optional: Detailed classification report for each model\n",
        "print(\"\\nBernoulliNB Classification Report:\\n\", classification_report(y_test, bnb_pred))\n",
        "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, svm_pred))\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, logreg_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltrtIXFxWBUS",
        "outputId": "a12ae9ff-dc37-48af-98cc-1a520977b952"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Predictions:\n",
            "BernoulliNB: [1 0 1]\n",
            "SVM: [1 0 1]\n",
            "Logistic Regression: [1 0 1]\n"
          ]
        }
      ],
      "source": [
        "# Test on custom tweets\n",
        "sample_tweets = [\"I love this!\", \"I hate that!\", \"It was okay, not great.\"]\n",
        "sample_vec = vectorizer.transform(sample_tweets)\n",
        "\n",
        "print(\"\\nSample Predictions:\")\n",
        "print(\"BernoulliNB:\", bnb.predict(sample_vec))\n",
        "print(\"SVM:\", svm.predict(sample_vec))\n",
        "print(\"Logistic Regression:\", logreg.predict(sample_vec))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open(\"logreg_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(logreg, f)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
